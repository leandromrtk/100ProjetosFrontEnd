{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leandromrtk/100ProjetosFrontEnd/blob/main/Pr%C3%A1tica_2_Deep_Learning_CNN_Classificador_de_imagens_de_animais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXrlT8DEnw1-"
      },
      "source": [
        "\n",
        "## **Prática: Reconhecimento de Imagens com Redes Neurais Convolucionais**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gz7da-lnw2A"
      },
      "source": [
        "Problema: Dada uma imagem, é um cachorro ou um gato?\n",
        "\n",
        "Assim como precisamos de dados históricos sobre clientes para que um algoritmo de Machine learming aprenda as regras para ter um crédito aprovado ou não (problema de classificação), para resolver esse problema precisamos primeiramente de muitas imagens de cachorros e gatos, para poder treinar um algoritmo de Deep Learning. Usaremos, portanto, uma abordagem de aprendizagem supervisionada, onde apresentaremos ao algoritmo diversas imagens, devidamente marcadas como sendo imagens de cães e gatos e então treinaremos o algoritmo. Ao final do treinamento, teremos um modelo que poderá receber novas imagens (desta vez não marcadas previamente) e então o modelo deverá ser capaz de classificar como sendo imagem de cão ou gato.\n",
        "\n",
        "Solução: Usar uma Rede Neural Convolucional para aprender recursos de imagens e assim prever se uma imagem contém um cachorro ou um gato."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh8Mhuhynw2A"
      },
      "source": [
        "## **Definição dos Dados**\n",
        "\n",
        "\n",
        "- Usamos os dados de treino para treinar o algoritmo e então criar o modelo preditivo.\n",
        "- Usamos os dados de validação, para avaliar o modelo durante o treinamento.\n",
        "- Usamos os dados de teste para validar a performance do modelo já treinado, ou seja, apresentamos ao modelo dados que ele não viu durante o treinamento, a fim de garantir que ele é capaz de fazer previsões.\n",
        "\n",
        "Fonte: https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "caminho = kagglehub.dataset_download(\"samuelcortinhas/cats-and-dogs-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", caminho)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svk4Hkpx6dbX",
        "outputId": "fef63dd7-c062-4625-893c-5d757346d7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'cats-and-dogs-image-classification' dataset.\n",
            "Path to dataset files: /kaggle/input/cats-and-dogs-image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variáveis básicas\n",
        "pasta_principal = caminho\n",
        "pasta_treino = caminho + \"/train\"\n",
        "pasta_testes = caminho + \"/test\"\n",
        "\n",
        "import os\n",
        "\n",
        "# Verifica se as pastas existem\n",
        "print(\"Pasta train existe:\", os.path.exists(pasta_treino))\n",
        "print(\"Pasta test existe:\", os.path.exists(pasta_testes))\n",
        "\n",
        "# Lista o que tem dentro de treino\n",
        "if os.path.exists(pasta_treino):\n",
        "    print(\"Conteúdo de train:\", os.listdir(pasta_treino))\n"
      ],
      "metadata": {
        "id": "io6lEOUN_JRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Mostrar uma imagem específica\n",
        "caminho_imagem = os.path.join(pasta_principal, \"train\", \"dogs\", \"dog_102.jpg\")\n",
        "\n",
        "# Verificar se o arquivo existe\n",
        "if os.path.exists(caminho_imagem):\n",
        "    display(Image(filename=caminho_imagem, width=300))\n",
        "else:\n",
        "    print(\"Arquivo não encontrado: \",caminho_imagem)"
      ],
      "metadata": {
        "id": "fGkUsFSo_cKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Processamento de dados**"
      ],
      "metadata": {
        "id": "vJ4wAcCLh6ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data Augmentation\n",
        "\n",
        "train_dir = \"/kaggle/input/cats-and-dogs-image-classification/train\"\n",
        "test_dir = \"/kaggle/input/cats-and-dogs-image-classification/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  #20 % PARA VALIDAÇÃO\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "S-EGt6niiBS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128, 128)   # redefinir  o tamanho das imagens\n",
        "batch_size = 32\n",
        "\n",
        "#DADOS DE TREINO\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"training\"    #80% TREINO\n",
        ")\n",
        "\n",
        "#DADOS DE VALIDAÇÃO = USAR DURANTE O TREINO\n",
        "val_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"validation\"   #20% VALIDAÇÃO\n",
        ")\n",
        "\n",
        "#DADOS DE TESTE = PREDIÇÃO EM DADOS/IMAGENS NÃO USADAS NO TREINO\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\"\n",
        ")"
      ],
      "metadata": {
        "id": "VlOwhQW4iNf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mapeamento de classes:\")\n",
        "print(train_gen.class_indices)\n",
        "print(\"Classes:\", train_gen.classes)\n",
        "print(\"Número de amostras:\", train_gen.samples)"
      ],
      "metadata": {
        "id": "x6r-Myyt04M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSXZN5TSnw2C"
      },
      "source": [
        "## **Construindo a Rede Neural Convolucional**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWeP2VO1nw2D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Define um simples CNN\n",
        "\n",
        "# Modelo sequencial: as camadas são empilhadas em sequência\n",
        "modelo_classificador = models.Sequential([\n",
        "\n",
        "    # Primeira camada de convolução:\n",
        "    # 32 filtros de tamanho 3x3, função de ativação ReLU.\n",
        "    # A entrada são imagens 128x128 com 3 canais (RGB).\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "\n",
        "    # Primeira camada de pooling:\n",
        "    # Reduz a dimensão da imagem (2x2) mantendo as principais características.\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    # Segunda camada de convolução:\n",
        "    # Aumenta o número de filtros para 64, aprendendo padrões mais complexos.\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "\n",
        "    # Segunda camada de pooling:\n",
        "    # Reduz novamente a dimensionalidade.\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    # Terceira camada de convolução:\n",
        "    # 128 filtros para capturar detalhes mais profundos da imagem.\n",
        "    layers.Conv2D(128, (3,3), activation='relu'),\n",
        "\n",
        "    # Terceira camada de pooling:\n",
        "    # Reduz a dimensionalidade final antes da parte densa.\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    # Flatten:\n",
        "    # Transforma os mapas de características 2D em um vetor 1D.\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Camada densa totalmente conectada:\n",
        "    # 128 neurônios, combina as características extraídas.\n",
        "    layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # Dropout:\n",
        "    # Desativa 50% dos neurônios durante o treino para evitar overfitting.\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    # Camada de saída:\n",
        "    # Um único neurônio com ativação sigmoid para classificação binária (0 ou 1).\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Compila o modelo antes do treino:\n",
        "\n",
        "modelo_classificador.compile(\n",
        "    optimizer='adam',              # Otimizador Adam: ajusta automaticamente a taxa de aprendizado\n",
        "    loss='binary_crossentropy',    # Função de perda usada em classificações binárias (0 ou 1)\n",
        "    metrics=['accuracy']           # Métrica de avaliação: acurácia\n",
        ")\n",
        "\n",
        "# Mostra o resumo da arquitetura da rede (opcional)\n",
        "# modelo_classificador.summary()\n",
        "\n",
        "# Treinamento do modelo:\n",
        "modelo_classificador.fit(\n",
        "    train_gen,                     # Conjunto de treinamento (gerador de imagens)\n",
        "    validation_data=val_gen,       # Conjunto de validação (usado para avaliar o desempenho)\n",
        "    epochs=10                      # Número de vezes que o modelo enxerga todos os dados para aprender\n",
        ")"
      ],
      "metadata": {
        "id": "EOg429Qd2uoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5gTgX05nw2N"
      },
      "source": [
        "## **Fazendo Previsões**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBTdTtwPnw2N"
      },
      "source": [
        "Vamos agora testar nosso modelo treinado com imagens que ele ainda não viu e que estão nos dados de teste.\n",
        "\n",
        "Para cada imagem de teste, carregamos as imagens com as mesmas dimensões usadas nas imagens de treino. Na sequência convertemos as imagens em um array e expandimos as dimensões. Então apresentamos as imagens ao classificador treinado nos passos anteriores. Por fim, verificamos o resultado da previsão e emitimos a informação se a imagem é de um gato ou cachorro."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e0LNCZWrjr2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJbAPL7Vnw2N"
      },
      "outputs": [],
      "source": [
        "# Função para prever imagem: Faz predição em uma única imagem usando o mesmo pré-processamento do treino\n",
        "\n",
        "def prever_imagem(modelo, caminho_imagem):\n",
        "\n",
        "    # 1. Carregar a imagem\n",
        "    img = image.load_img(caminho_imagem, target_size=(128, 128))  # Mesmo tamanho\n",
        "    display(Image(filename=caminho_imagem, width=300))  #mostrar a imagem original\n",
        "\n",
        "    # 2. Converter para array e aplicar mesmo pré-processamento\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Adicionar dimensão do batch\n",
        "    img_array /= 255.0  # Mesma normalização: 1./255\n",
        "\n",
        "    # 3. Fazer predição\n",
        "    predicao = modelo.predict(img_array)[0][0]\n",
        "\n",
        "    # 4. Interpretar resultado\n",
        "    if predicao > 0.5:\n",
        "        resultado = \"É um Cachorro\"\n",
        "        confianca = predicao\n",
        "    else:\n",
        "        resultado = \"É um gato\"\n",
        "        confianca = 1 - predicao\n",
        "\n",
        "    print(\"Resultado: \", resultado)\n",
        "    print(\"Confiança: \", confianca)\n",
        "\n",
        "    return predicao"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USAR A FUNÇÃO:\n",
        "caminho_imagem_predicao = os.path.join(pasta_principal, \"test\", \"dogs\", \"dog_130.jpg\")\n",
        "caminho_imagem_predicao_2 = os.path.join(pasta_principal, \"test\", \"cats\", \"cat_118.jpg\")\n",
        "\n",
        "if os.path.exists(caminho_imagem_predicao_2):\n",
        "    prever_imagem(modelo_classificador, caminho_imagem_predicao_2)\n",
        "else:\n",
        "    print(\"Arquivo não encontrado:\", caminho_imagem_predicao_2)"
      ],
      "metadata": {
        "id": "RXpSYnNyi0LR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}